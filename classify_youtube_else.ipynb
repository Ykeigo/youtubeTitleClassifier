{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://qiita.com/m__k/items/98ff5fb4a4cb4e1eba26\n",
    "↑ここのやつを動かしている\n",
    "単語ベクトルはkaggleからとってきたgloveの単語ベクトル"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torchtext\n",
    "import torchtext\n",
    "from torchtext import data\n",
    "from torchtext import datasets\n",
    "from torchtext.vocab import GloVe\n",
    "from torchtext.vocab import Vectors\n",
    "\n",
    "# pytorch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "\n",
    "# その他もろもろ\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from itertools import chain\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# 最後にattentionを可視化するときに使います。\n",
    "import itertools\n",
    "import random\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "import MeCab\n",
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nltk_analyzer(\"I have a pen.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "me = MeCab.Tagger (\"-Owakati\")\n",
    "def mecab_tokenizer(text):\n",
    "    return me.parse(text).split()\n",
    "\n",
    "# train.tsv, test.tsvをここに置いとく\n",
    "imdb_dir = \"./datas\"\n",
    "\n",
    "# glove.6B.200d.txtをここに置いとく\n",
    "word_embedding_dir = \"./\"\n",
    "\n",
    "TEXT = data.Field(sequential=True, tokenize=mecab_tokenizer, lower=True, include_lengths=True, batch_first=True)\n",
    "TEXT_nobatch = data.Field(sequential=True, tokenize=mecab_tokenizer, lower=True, include_lengths=True, batch_first=False)\n",
    "\n",
    "LABEL = data.Field(sequential=False, use_vocab=False, is_target=True)\n",
    "\n",
    "train, test = data.TabularDataset.splits(\n",
    "      path=imdb_dir, train='train_class.tsv', test='test_class.tsv', format='tsv',\n",
    "      fields=[('Text', TEXT), ('Label', LABEL)])\n",
    "\n",
    "#glove_vectors = Vectors(name=word_embedding_dir + \"glove.6B.200d.txt\")\n",
    "\n",
    "#TEXT.build_vocab(train, vectors=glove_vectors, min_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['友人', '代表', 'の', 'スピーチ', '、', '独', '女', 'は', 'どう', 'こなし', 'て', 'いる', '？']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.examples[0].Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "kakko_labels = [0,0]\n",
    "\n",
    "for i, ex in enumerate(test.examples):\n",
    "        #print(i.Text)\n",
    "        if \"【\" in ex.Text or \"】\" in ex.Text:\n",
    "            kakko_labels[int(ex.Label)] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[47, 506]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kakko_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = gensim.models.KeyedVectors.load_word2vec_format(\"model.vec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(embedding.index2word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#device = torch.device(\"cpu\")\n",
    "\n",
    "BATCH_SIZE = 100 # バッチサイズ\n",
    "EMBEDDING_DIM = 300 # 単語の埋め込み次元数\n",
    "LSTM_DIM = 128 # LSTMの隠れ層の次元数\n",
    "#VOCAB_SIZE = len(embedding.index2word) # 全単語数\n",
    "TAG_SIZE = 2 # 今回はネガポジ判定を行うのでネットワークの最後のサイズは2\n",
    "DA = 128 # AttentionをNeural Networkで計算する際の重み行列のサイズ\n",
    "R = 1 # Attentionの数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiLSTMEncoder(nn.Module):\n",
    "    def __init__(self, embedding_dim, lstm_dim):\n",
    "        super(BiLSTMEncoder, self).__init__() #親の__init__で一回初期化する\n",
    "        self.lstm_dim = lstm_dim\n",
    "        \n",
    "        # bidirectional=Trueでお手軽に双方向のLSTMにできる\n",
    "        self.bilstm = nn.LSTM(embedding_dim, lstm_dim, batch_first=True, bidirectional=True)\n",
    "\n",
    "    def forward(self, sentences):\n",
    "        #print(\"forward\")\n",
    "        #分かち書きテキストが来るのでembeddingにする\n",
    "        embeds = []\n",
    "        for s in sentences:\n",
    "            #print(s)\n",
    "            vecs = []\n",
    "            for w in s:\n",
    "                if w in embedding:\n",
    "                    vecs.append(embedding[w])\n",
    "                else:\n",
    "                    vecs.append(np.zeros(EMBEDDING_DIM))\n",
    "            #vecs = torch.tensor(vecs)\n",
    "            #print(vecs.shape)\n",
    "            embeds.append(vecs)\n",
    "            \n",
    "        embeds = torch.tensor(embeds).float()\n",
    "        #print(\"embeddings shape {}\".format(embeds.shape))\n",
    "        \n",
    "        # 各隠れ層のベクトルがほしいので第１戻り値を受け取る\n",
    "        out, _ = self.bilstm(embeds)\n",
    "\n",
    "        # 前方向と後ろ方向の各隠れ層のベクトルを結合したままの状態で返す\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelfAttention(nn.Module):\n",
    "  def __init__(self, lstm_dim, da, r):\n",
    "    super(SelfAttention, self).__init__()\n",
    "    self.lstm_dim = lstm_dim\n",
    "    self.da = da\n",
    "    self.r = r\n",
    "    self.main = nn.Sequential(\n",
    "        # Bidirectionalなので各隠れ層のベクトルの次元は２倍のサイズになってます。\n",
    "        nn.Linear(lstm_dim * 2, da), \n",
    "        nn.Tanh(),\n",
    "        nn.Linear(da, r)\n",
    "    )\n",
    "  def forward(self, out):\n",
    "    return F.softmax(self.main(out), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelfAttentionClassifier(nn.Module):\n",
    "  def __init__(self, lstm_dim, da, r, tagset_size):\n",
    "    super(SelfAttentionClassifier, self).__init__()\n",
    "    self.lstm_dim = lstm_dim\n",
    "    self.r = r\n",
    "    self.attn = SelfAttention(lstm_dim, da, r)\n",
    "    self.main = nn.Linear(lstm_dim * 2 * r, tagset_size)\n",
    "\n",
    "  def forward(self, out):\n",
    "    attention_weight = self.attn(out)\n",
    "    \n",
    "    feats = torch.tensor([], device=device)\n",
    "    for i in range(self.r):\n",
    "        m1 = (out * attention_weight[:,:,i].unsqueeze(2)).sum(dim=1)\n",
    "        feats = torch.cat([feats, m1], dim = 1)\n",
    "    #m1 = (out * attention_weight[:,:,0].unsqueeze(2)).sum(dim=1)\n",
    "    #m2 = (out * attention_weight[:,:,1].unsqueeze(2)).sum(dim=1)\n",
    "    #m3 = (out * attention_weight[:,:,2].unsqueeze(2)).sum(dim=1)\n",
    "    #feats = torch.cat([m1, m2, m3], dim=1)\n",
    "    return F.log_softmax(self.main(feats)), attention_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeWordsBatch(examples, batch_size):\n",
    "    datas = []\n",
    "    for i in examples.examples:\n",
    "        #print(i.Text)\n",
    "        datas.append([i.Text, i.Label])\n",
    "    \n",
    "    #train, test = train_test_split(datas, test_size=0.2, shuffle = True)\n",
    "    \n",
    "    datas = sorted(datas, key=lambda x: len(x[0]), reverse=True)\n",
    "    #print(datas)\n",
    "    batchs = []\n",
    "    for i in range(0, len(datas), batch_size):\n",
    "        batch = datas[i : min(len(datas), i+batch_size)]\n",
    "        \n",
    "        maxLengh = len(batch[0][0])\n",
    "        for j in range(len(batch)):\n",
    "            #if len(batch[j][0]) < maxLengh:\n",
    "                #print(\"pad\")\n",
    "            batch[j][0] += [\"[PAD]\"]*(maxLengh-len(batch[j][0]))\n",
    "            #print(batch[j])\n",
    "        batchs.append(np.array(batch))\n",
    "    \n",
    "    return batchs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = BiLSTMEncoder(EMBEDDING_DIM, LSTM_DIM).to(device)\n",
    "classifier = SelfAttentionClassifier(LSTM_DIM, DA, R, TAG_SIZE).to(device)\n",
    "loss_function = nn.NLLLoss()\n",
    "\n",
    "# 複数のモデルを from itertools import chain で囲えばoptimizerをまとめて1つにできる\n",
    "optimizer = optim.Adam(chain(encoder.parameters(), classifier.parameters()), lr=0.001)\n",
    "\n",
    "train_batch = makeWordsBatch(train, BATCH_SIZE)\n",
    "test_batch = makeWordsBatch(test, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-13-1f20314e62cf>:20: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.log_softmax(self.main(feats)), attention_weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 \t loss 43.71581791341305\n",
      "epoch 1 \t loss 31.060765251517296\n",
      "epoch 2 \t loss 25.640651881694794\n",
      "epoch 3 \t loss 26.564660646021366\n",
      "epoch 4 \t loss 20.542380791157484\n",
      "epoch 5 \t loss 14.590887319296598\n",
      "epoch 6 \t loss 12.521175934001803\n",
      "epoch 7 \t loss 10.498157802969217\n",
      "epoch 8 \t loss 9.344554176554084\n",
      "epoch 9 \t loss 8.329964959761128\n",
      "epoch 10 \t loss 6.985395222029183\n",
      "epoch 11 \t loss 5.840874685673043\n",
      "epoch 12 \t loss 4.79038558609318\n",
      "epoch 13 \t loss 3.8382821249833796\n",
      "epoch 14 \t loss 3.123822103982093\n",
      "epoch 15 \t loss 3.1677562475961167\n",
      "epoch 16 \t loss 3.0932017067971174\n",
      "epoch 17 \t loss 3.188196316783433\n",
      "epoch 18 \t loss 2.5356567108538\n",
      "epoch 19 \t loss 2.199875472644635\n",
      "epoch 20 \t loss 1.6431942588624224\n",
      "epoch 21 \t loss 2.660175201614038\n",
      "epoch 22 \t loss 1.8221130265592365\n",
      "epoch 23 \t loss 1.1801957328498247\n",
      "epoch 24 \t loss 0.94119790438981\n",
      "epoch 25 \t loss 0.8679495206233696\n",
      "epoch 26 \t loss 0.6514129947954643\n",
      "epoch 27 \t loss 0.9034361888498097\n",
      "epoch 28 \t loss 1.4792188552382868\n",
      "epoch 29 \t loss 0.6381396747237886\n",
      "epoch 30 \t loss 0.839923484935639\n",
      "epoch 31 \t loss 0.7803754378987833\n",
      "epoch 32 \t loss 0.8947422050794103\n",
      "epoch 33 \t loss 0.5692789069053106\n",
      "epoch 34 \t loss 0.6401056429972414\n",
      "epoch 35 \t loss 0.5661615637072828\n",
      "epoch 36 \t loss 1.3746702380465194\n",
      "epoch 37 \t loss 1.431224271243991\n",
      "epoch 38 \t loss 0.4385735605392256\n",
      "epoch 39 \t loss 0.3028336068164208\n",
      "epoch 40 \t loss 0.2725139986642944\n",
      "epoch 41 \t loss 0.23986184081240935\n",
      "epoch 42 \t loss 0.21692829363837518\n",
      "epoch 43 \t loss 0.20266773689945694\n",
      "epoch 44 \t loss 0.19242594882439334\n",
      "epoch 45 \t loss 0.18415881039845772\n",
      "epoch 46 \t loss 0.17723308603518717\n",
      "epoch 47 \t loss 0.1713896677467801\n",
      "epoch 48 \t loss 0.16640421107328507\n",
      "epoch 49 \t loss 0.16210130260685673\n",
      "epoch 50 \t loss 0.1583535466664614\n"
     ]
    }
   ],
   "source": [
    "losses = []\n",
    "stop_count = 0\n",
    "best_loss = 10000\n",
    "\n",
    "for epoch in range(100):\n",
    "    epoch_loss = 0\n",
    "    #print(train_batch)\n",
    "    for idx, batch in enumerate(train_batch):\n",
    "        #print(idx)\n",
    "        #print(batch)\n",
    "        \n",
    "        batch_loss = 0\n",
    "        encoder.zero_grad()\n",
    "        classifier.zero_grad()\n",
    "\n",
    "        text_tensor = batch[:, 0]\n",
    "        #print(\"text tensor shape{}\".format(text_tensor.shape))\n",
    "        label_tensor = batch[:, 1].astype(np.long)\n",
    "        label_tensor = torch.from_numpy(label_tensor)\n",
    "        #print(label_tensor.size())\n",
    "        out = encoder(text_tensor)\n",
    "        #print(out.size())\n",
    "        score, attn = classifier(out)\n",
    "        #print(score.size())\n",
    "        #print(score)\n",
    "        #print(label_tensor.size())\n",
    "        #print(label_tensor)\n",
    "        batch_loss = loss_function(score, label_tensor)\n",
    "        batch_loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += batch_loss.item()\n",
    "        \n",
    "        #break\n",
    "        \n",
    "    print(\"epoch\", epoch, \"\\t\" , \"loss\", epoch_loss)\n",
    "    \n",
    "    #終了条件（ガバガバ）\n",
    "    if best_loss - epoch_loss < 0.01:\n",
    "        #print(\"更新できず\")\n",
    "        stop_count += 1\n",
    "        if stop_count > 5:\n",
    "            break\n",
    "    else:\n",
    "        stop_count = 0\n",
    "        \n",
    "    if best_loss > epoch_loss:\n",
    "        best_loss = epoch_loss\n",
    "    \n",
    "    losses.append(epoch_loss)\n",
    "#epoch 0     loss 97.37978366017342\n",
    "#epoch 1     loss 50.07680431008339\n",
    "#epoch 2     loss 27.79373042844236\n",
    "#epoch 3     loss 9.353876578621566\n",
    "#epoch 4     loss 1.9509600398596376\n",
    "#epoch 5     loss 0.22650832029466983\n",
    "#epoch 6     loss 0.021685686125238135\n",
    "#epoch 7     loss 0.011305359620109812\n",
    "#epoch 8     loss 0.007448446772286843\n",
    "#epoch 9     loss 0.005398457038154447"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1577a7ac0>]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.plot(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(encoder.state_dict(), \"encoder.trained\")\n",
    "torch.save(classifier.state_dict(), \"classifier.trained\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-13-1f20314e62cf>:20: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.log_softmax(self.main(feats)), attention_weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "1600\n",
      "1700\n",
      "1723\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    positive       0.97      0.93      0.95       946\n",
      "    negative       0.92      0.97      0.94       777\n",
      "\n",
      "    accuracy                           0.95      1723\n",
      "   macro avg       0.95      0.95      0.95      1723\n",
      "weighted avg       0.95      0.95      0.95      1723\n",
      "\n"
     ]
    }
   ],
   "source": [
    "answer = []\n",
    "prediction = []\n",
    "\n",
    "zero_predictions = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in test_batch:\n",
    "\n",
    "        text_tensor = batch[:, 0]\n",
    "        #print(\"text tensor shape{}\".format(text_tensor.shape))\n",
    "        label_tensor = batch[:, 1].astype(np.long)\n",
    "        label_tensor = torch.from_numpy(label_tensor)\n",
    "\n",
    "        out = encoder(text_tensor)\n",
    "        #print(out)\n",
    "        score, _ = classifier(out)\n",
    "        _, pred = torch.max(score, 1)\n",
    "        #print(score[:,0].tolist())\n",
    "        #ラベル0の出力を全部記録する\n",
    "        zero_predictions = zero_predictions+score[:,0].tolist()\n",
    "        print(len(zero_predictions))\n",
    "\n",
    "        prediction += list(pred.cpu().numpy())\n",
    "        answer += list(label_tensor.cpu().numpy())\n",
    "print(classification_report(prediction, answer, target_names=['positive', 'negative']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-ba4ceff2b710>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mzero_predictions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzero_predictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "#print(zero_predictions)\n",
    "%matplotlib inline\n",
    "\n",
    "zero_predictions.sort()\n",
    "\n",
    "plt.plot(zero_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[list(['「', 'めざまし', 'テレビ', '」', '大塚', '範一', 'アナ', 'の', '“', '卒業', '”', 'が', 'ネット', '上', 'で', '話題', '[PAD]'])]\n",
      "tensor([[0]])\n",
      "tensor([-1.3947e-05, -1.1177e+01], grad_fn=<SelectBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-13-1f20314e62cf>:20: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.log_softmax(self.main(feats)), attention_weight\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "【正解】negative\t【予測】negative<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " <span style=\"background-color: #FFECEC\">「</span> <span style=\"background-color: #FFFAFA\">めざまし</span> <span style=\"background-color: #FFE1E1\">テレビ</span> <span style=\"background-color: #FFFAFA\">」</span> <span style=\"background-color: #FFE2E2\">大塚</span> <span style=\"background-color: #FFFCFC\">範一</span> <span style=\"background-color: #FFEBEB\">アナ</span> <span style=\"background-color: #FFFDFD\">の</span> <span style=\"background-color: #FFEDED\">“</span> <span style=\"background-color: #FFF9F9\">卒業</span> <span style=\"background-color: #FFF9F9\">”</span> <span style=\"background-color: #FFFEFE\">が</span> <span style=\"background-color: #FFFEFE\">ネット</span> <span style=\"background-color: #FFFFFF\">上</span> <span style=\"background-color: #FFFEFE\">で</span> <span style=\"background-color: #FF8B8B\">話題</span> <span style=\"background-color: #FFFEFE\">[PAD]</span><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def highlight(word, attn):\n",
    "    html_color = '#%02X%02X%02X' % (255, int(255*(1 - attn)), int(255*(1 - attn)))\n",
    "    return '<span style=\"background-color: {}\">{}</span>'.format(html_color, word)\n",
    "\n",
    "def mk_html(sentence, attns):\n",
    "    html = \"\"\n",
    "    for word, attn in zip(sentence, attns):\n",
    "        html += ' ' + highlight(\n",
    "            word,\n",
    "            attn\n",
    "        )\n",
    "        #print(word)\n",
    "        #print(TEXT.vocab.itos[word])\n",
    "    return html\n",
    "\n",
    "id2ans = {1: 'positive', 0:'negative'}\n",
    "\n",
    "#print(id2ans[1])\n",
    "\n",
    "test_batch_1 = makeWordsBatch(test, 1)\n",
    "\n",
    "n = random.randrange(len(test_batch_1))\n",
    "\n",
    "for batch in itertools.islice(test_batch_1, n-1,n):\n",
    "    text_tensor = batch[:, 0]\n",
    "    print(text_tensor)\n",
    "    #print(\"text tensor shape{}\".format(text_tensor.shape))\n",
    "    label_tensor = batch[:, 1].astype(np.long)\n",
    "    label_tensor = torch.from_numpy(label_tensor)\n",
    "    #print(label_tensor[0])\n",
    "    \n",
    "    encoder_outputs = encoder(text_tensor)\n",
    "    output, attn = classifier(encoder_outputs)\n",
    "    pred = output.data.max(1, keepdim=True)[1]\n",
    "    print(pred)\n",
    "    print(output[0])\n",
    "    display(HTML('【正解】' + id2ans[int(label_tensor)] + '\\t【予測】' + id2ans[int(pred)] + '<br><br>'))\n",
    "    #print(attn)\n",
    "    for i in range(attn.size()[2]):\n",
    "      display(HTML(mk_html(text_tensor[0], attn.data[0,:,i]) + '<br><br>'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "【神回】バズレンダでマナが大変なことに?!【驚愕】\n",
      "[['【' '神' '回' '】' 'バズレンダ' 'で' 'マナ' 'が' '大変' 'な' 'こと' 'に' '?!【' '驚愕' '】']]\n",
      "tensor([-1.5796e+01, -1.1921e-07], grad_fn=<SelectBackward>)\n",
      "再生回数：1182330回\n",
      "tensor([[1]])\n",
      "positive\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-13-1f20314e62cf>:20: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.log_softmax(self.main(feats)), attention_weight\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\t【予測】positive<br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " <span style=\"background-color: #FFFEFE\">【</span> <span style=\"background-color: #FFFFFF\">神</span> <span style=\"background-color: #FFE6E6\">回</span> <span style=\"background-color: #FF4D4D\">】</span> <span style=\"background-color: #FFFEFE\">バズレンダ</span> <span style=\"background-color: #FFFFFF\">で</span> <span style=\"background-color: #FFFEFE\">マナ</span> <span style=\"background-color: #FFFFFF\">が</span> <span style=\"background-color: #FFFFFF\">大変</span> <span style=\"background-color: #FFFFFF\">な</span> <span style=\"background-color: #FFFFFF\">こと</span> <span style=\"background-color: #FFFFFF\">に</span> <span style=\"background-color: #FFFFFF\">?!【</span> <span style=\"background-color: #FFFFFF\">驚愕</span> <span style=\"background-color: #FFCBCB\">】</span><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "text = input()\n",
    "text_tensor = np.array([mecab_tokenizer(text)])\n",
    "print(text_tensor)\n",
    "\n",
    "id2ans = {1: 'positive', 0:'negative'}\n",
    "\n",
    "encoder_outputs = encoder(text_tensor)\n",
    "output, attn = classifier(encoder_outputs)\n",
    "pred = output.data.max(1, keepdim=True)[1]\n",
    "\n",
    "print(output[0])\n",
    "#print(\"{:.02f}\".format(np.power(np.e , float(output[0][0]))))\n",
    "print(\"再生回数：{:.0f}回\".format(-300 * np.power(float(output[0][0]),3) ))\n",
    "print(pred)\n",
    "print(id2ans[int(pred)])\n",
    "display(HTML( '\\t【予測】' + id2ans[int(pred)] + '<br><br>'))\n",
    "#print(attn)\n",
    "for i in range(attn.size()[2]):\n",
    "  display(HTML(mk_html(text_tensor[0], attn.data[0,:,i]) + '<br><br>'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "新型フラフープで超効率独自シェイプアップ術！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
