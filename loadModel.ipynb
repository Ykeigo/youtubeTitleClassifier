{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torchtext\n",
    "import torchtext\n",
    "from torchtext import data\n",
    "from torchtext import datasets\n",
    "\n",
    "# pytorch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# その他もろもろ\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import MeCab\n",
    "import gensim\n",
    "\n",
    "import socket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "me = MeCab.Tagger (\"-Owakati\")\n",
    "def mecab_tokenizer(text):\n",
    "    return me.parse(text).split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = gensim.models.KeyedVectors.load_word2vec_format(\"model.vec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#device = torch.device(\"cpu\")\n",
    "\n",
    "BATCH_SIZE = 100 # バッチサイズ\n",
    "EMBEDDING_DIM = 300 # 単語の埋め込み次元数\n",
    "LSTM_DIM = 128 # LSTMの隠れ層の次元数\n",
    "#VOCAB_SIZE = len(embedding.index2word) # 全単語数\n",
    "TAG_SIZE = 2 # 今回はネガポジ判定を行うのでネットワークの最後のサイズは2\n",
    "DA = 128 # AttentionをNeural Networkで計算する際の重み行列のサイズ\n",
    "R = 1 # Attentionの数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiLSTMEncoder(nn.Module):\n",
    "    def __init__(self, embedding_dim, lstm_dim):\n",
    "        super(BiLSTMEncoder, self).__init__() #親の__init__で一回初期化する\n",
    "        self.lstm_dim = lstm_dim\n",
    "        \n",
    "        # bidirectional=Trueでお手軽に双方向のLSTMにできる\n",
    "        self.bilstm = nn.LSTM(embedding_dim, lstm_dim, batch_first=True, bidirectional=True)\n",
    "\n",
    "    def forward(self, sentences):\n",
    "        #print(\"forward\")\n",
    "        #分かち書きテキストが来るのでembeddingにする\n",
    "        embeds = []\n",
    "        for s in sentences:\n",
    "            #print(s)\n",
    "            vecs = []\n",
    "            for w in s:\n",
    "                if w in embedding:\n",
    "                    vecs.append(embedding[w])\n",
    "                else:\n",
    "                    vecs.append(np.zeros(EMBEDDING_DIM))\n",
    "            #vecs = torch.tensor(vecs)\n",
    "            #print(vecs.shape)\n",
    "            embeds.append(vecs)\n",
    "            \n",
    "        embeds = torch.tensor(embeds).float()\n",
    "        #print(\"embeddings shape {}\".format(embeds.shape))\n",
    "        \n",
    "        # 各隠れ層のベクトルがほしいので第１戻り値を受け取る\n",
    "        out, _ = self.bilstm(embeds)\n",
    "\n",
    "        # 前方向と後ろ方向の各隠れ層のベクトルを結合したままの状態で返す\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelfAttention(nn.Module):\n",
    "  def __init__(self, lstm_dim, da, r):\n",
    "    super(SelfAttention, self).__init__()\n",
    "    self.lstm_dim = lstm_dim\n",
    "    self.da = da\n",
    "    self.r = r\n",
    "    self.main = nn.Sequential(\n",
    "        # Bidirectionalなので各隠れ層のベクトルの次元は２倍のサイズになってます。\n",
    "        nn.Linear(lstm_dim * 2, da), \n",
    "        nn.Tanh(),\n",
    "        nn.Linear(da, r)\n",
    "    )\n",
    "  def forward(self, out):\n",
    "    return F.softmax(self.main(out), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelfAttentionClassifier(nn.Module):\n",
    "  def __init__(self, lstm_dim, da, r, tagset_size):\n",
    "    super(SelfAttentionClassifier, self).__init__()\n",
    "    self.lstm_dim = lstm_dim\n",
    "    self.r = r\n",
    "    self.attn = SelfAttention(lstm_dim, da, r)\n",
    "    self.main = nn.Linear(lstm_dim * 2 * r, tagset_size)\n",
    "\n",
    "  def forward(self, out):\n",
    "    attention_weight = self.attn(out)\n",
    "    \n",
    "    feats = torch.tensor([], device=device)\n",
    "    for i in range(self.r):\n",
    "        m1 = (out * attention_weight[:,:,i].unsqueeze(2)).sum(dim=1)\n",
    "        feats = torch.cat([feats, m1], dim = 1)\n",
    "    #m1 = (out * attention_weight[:,:,0].unsqueeze(2)).sum(dim=1)\n",
    "    #m2 = (out * attention_weight[:,:,1].unsqueeze(2)).sum(dim=1)\n",
    "    #m3 = (out * attention_weight[:,:,2].unsqueeze(2)).sum(dim=1)\n",
    "    #feats = torch.cat([m1, m2, m3], dim=1)\n",
    "    return F.log_softmax(self.main(feats)), attention_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder = BiLSTMEncoder(EMBEDDING_DIM, LSTM_DIM).to(device)\n",
    "encoder.load_state_dict(torch.load(\"encoder.trained\"))\n",
    "classifier = SelfAttentionClassifier(LSTM_DIM, DA, R, TAG_SIZE).to(device)\n",
    "classifier.load_state_dict(torch.load(\"classifier.trained\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classifier\n",
      "[['classifier']]\n",
      "tensor([-0.7194, -0.6676], grad_fn=<SelectBackward>)\n",
      "再生回数：112回\n",
      "tensor([[1]])\n",
      "positive\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-7-1f20314e62cf>:20: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.log_softmax(self.main(feats)), attention_weight\n"
     ]
    }
   ],
   "source": [
    "text = input()\n",
    "text_tensor = np.array([mecab_tokenizer(text)])\n",
    "print(text_tensor)\n",
    "\n",
    "id2ans = {1: 'positive', 0:'negative'}\n",
    "\n",
    "encoder_outputs = encoder(text_tensor)\n",
    "output, attn = classifier(encoder_outputs)\n",
    "pred = output.data.max(1, keepdim=True)[1]\n",
    "\n",
    "print(output[0])\n",
    "#print(\"{:.02f}\".format(np.power(np.e , float(output[0][0]))))\n",
    "print(\"再生回数：{:.0f}回\".format(-300 * np.power(float(output[0][0]),3) ))\n",
    "print(pred)\n",
    "print(id2ans[int(pred)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:\n",
    "    # IPアドレスとポートを指定\n",
    "    s.bind(('localhost', 50007))\n",
    "    # 1 接続\n",
    "    s.listen(1)\n",
    "    # connection するまで待つ\n",
    "    while True:\n",
    "        # 誰かがアクセスしてきたら、コネクションとアドレスを入れる\n",
    "        conn, addr = s.accept()\n",
    "        with conn:\n",
    "            while True:\n",
    "                # データを受け取る\n",
    "                data = conn.recv(1024)\n",
    "                if not data:\n",
    "                    break\n",
    "                print('data : {}, addr: {}'.format(data, addr))\n",
    "                # クライアントにデータを返す(b -> byte でないといけない)\n",
    "                conn.sendall(b'Received: ' + data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
